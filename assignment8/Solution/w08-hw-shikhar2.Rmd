---
title: "Week 8 - Homework"
author: "STAT 420, Summer 2019, SKhanna, Netid: Shikhar2"
date: '7/5/2019'
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---


***

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.alin = "center")
```

## Exercise 1 (Writing Functions)

**(a)** Write a function named `diagnostics` that takes as input the arguments:

- `model`, an object of class `lm()`, that is a model fit via `lm()`
- `pcol`, for controlling point colors in plots, with a default value of `grey`
- `lcol`, for controlling line colors in plots, with a default value of `dodgerblue`
- `alpha`, the significance level of any test that will be performed inside the function, with a default value of `0.05`
- `plotit`, a logical value for controlling display of plots with default value `TRUE`
- `testit`, a logical value for controlling outputting the results of tests with default value `TRUE`

The function should output:

- A list with two elements when `testit` is `TRUE`:
    - `p_val`, the p-value for the Shapiro-Wilk test for assessing normality
    - `decision`, the decision made when performing the Shapiro-Wilk test using the `alpha` value input to the function. "Reject" if the null hypothesis is rejected, otherwise "Fail to Reject."
- Two plots, side-by-side, when `plotit` is `TRUE`:
    - A fitted versus residuals plot that adds a horizontal line at $y = 0$, and labels the $x$-axis "Fitted" and the $y$-axis "Residuals." The points and line should be colored according to the input arguments. Give the plot a title. 
    - A Normal Q-Q plot of the residuals that adds the appropriate line using `qqline()`. The points and line should be colored according to the input arguments. Be sure the plot has a title. 
    
```{r}
diagnostics = function(model,pcol='grey',lcol='dodgerblue',alpha=0.05,plotit=TRUE,testit=TRUE){
	p=shapiro.test(resid(model))$p.value
	decision=ifelse(p<alpha,"Reject","Fail to Reject")
	if (testit==TRUE)
		{
		return(list("p_val"=p,"decision"=decision))
		}
	if (plotit==TRUE)
		{
		par(mfrow = c(1, 2))
		plot(fitted(model), resid(model), col = pcol, pch = 20,
		xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual")
		abline(h = 0, col = lcol, lwd = 2)
		
		qqnorm(resid(model), main = "Normal Q-Q Plot", col = pcol)
		qqline(resid(model), col = lcol, lwd = 2)
		}
	}
```


Consider using this function to help with the remainder of the assignment as well.

**(b)** Run the following code.

```{r}
set.seed(420)

data_1 = data.frame(x = runif(n = 30, min = 0, max = 10),
                    y = rep(x = 0, times = 30))
data_1$y = with(data_1, 2 + 1 * x + rexp(n = 30))
fit_1 = lm(y ~ x, data = data_1)

data_2 = data.frame(x = runif(n = 20, min = 0, max = 10),
                    y = rep(x = 0, times = 20))
data_2$y = with(data_2, 5 + 2 * x + rnorm(n = 20))
fit_2 = lm(y ~ x, data = data_2)

data_3 = data.frame(x = runif(n = 40, min = 0, max = 10),
                    y = rep(x = 0, times = 40))
data_3$y = with(data_3, 2 + 1 * x + rnorm(n = 40, sd = x))
fit_3 = lm(y ~ x, data = data_3)
```

```{r, eval = TRUE}
diagnostics(fit_1, plotit = FALSE)$p_val
diagnostics(fit_2, plotit = FALSE)$decision
diagnostics(fit_1, testit = FALSE, pcol = "black", lcol = "black")
diagnostics(fit_2, testit = FALSE, pcol = "grey", lcol = "green")
diagnostics(fit_3)
```

***

## Exercise 2 (Prostate Cancer Data)

For this exercise, we will use the `prostate` data, which can be found in the `faraway` package. After loading the `faraway` package, use `?prostate` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
library(faraway)
library(lmtest)
```

**(a)** Fit an additive multiple regression model with `lpsa` as the response and the remaining variables in the `prostate` dataset as predictors. Report the $R^2$ value for this model.

```{r}
mod_prost = lm(lpsa~., data=prostate)
summary(mod_prost)$r.squared
```


**(b)** Check the constant variance assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}

plot(fitted(mod_prost), resid(mod_prost), col = "dodgerblue", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual")
abline(h = 0, col = "orange", lwd = 2)

bptest(mod_prost)
```

Comment: looking at the Plot and the BP figures it appears that Fitted vs Residual graph does not have any apparent pattern and the Residual variance apprears to be consistent across the fitted values. From the BP test the same is confirmed, since the p value is greater than alpha, hence we fail to reject that Constant variance is a suspect.


**(c)** Check the normality assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
qqnorm(resid(mod_prost), main = "Q-Q Plot", col = "dodgerblue")
qqline(resid(mod_prost), col = "dodgerblue", lwd = 2)
shapiro.test(resid(mod_prost)) 
```

Comment: looking at the Plot and the shapiro test figures it appears that the QQ graph appears to be fairly along the line. From the shapiro test the same is confirmed, since the p value is greater than alpha, hence we fail to reject that Normality is a suspect.

**(d)** Check for any high leverage observations. Report any observations you determine to have high leverage.

```{r}
prostate[c(hatvalues(mod_prost) > 2 * mean(hatvalues(mod_prost))),]
```


**(e)** Check for any influential observations. Report any observations you determine to be influential.

```{r}
cd_mod_prost = cooks.distance(mod_prost)
prostate[c(cd_mod_prost > 4 / length(cd_mod_prost)),]
```


**(f)** Refit the additive multiple regression model without any points you identified as influential. Compare the coefficients of this fitted model to the previously fitted model.

```{r}
mod_prost_fix = lm(lpsa~.,
                    data = prostate,
                    subset = cd_mod_prost <= 4 / length(cd_mod_prost))

coef(mod_prost)
coef(mod_prost_fix)
```

Comment: The beta coeficients did not change much bit the intercept changed significantly and infact changed from positive to negative

**(g)** Create a data frame that stores the observations that were "removed" because they were influential. Use the two models you have fit to make predictions with these observations. Comment on the difference between these two sets of predictions.

```{r}
prost_removed = prostate[c(cd_mod_prost > 4 / length(cd_mod_prost)),]

predict(mod_prost, newdata = prost_removed)
predict(mod_prost_fix, newdata = prost_removed)
```

Comment: Removing the influential points did change the beta parameters so we can expect difference in the prediction values as well. This is what is apparent from the above two preidction results. 

***

## Exercise 3 (Why Bother?)

**Why** do we care about violations of assumptions? One key reason is that the distributions of the parameter esimators that we have used are all reliant on these assumptions. When the assumptions are violated, the distributional results are not correct, so our tests are garbage. **Garbage In, Garbage Out!**

Consider the following setup that we will use for the remainder of the exercise. We choose a sample size of 50.

```{r}
n = 50
set.seed(420)
x_1 = runif(n, 0, 5)
x_2 = runif(n, -2, 2)
```

Consider the model,

\[
Y = 4 + 1 x_1 + 0 x_2 + \epsilon.
\]

That is,

- $\beta_0$ = 4
- $\beta_1$ = 1
- $\beta_2$ = 0

We now simulate `y_1` in a manner that does **not** violate any assumptions, which we will verify. In this case $\epsilon \sim N(0, 1).$

```{r}
set.seed(1)
y_1 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = 1)
fit_1 = lm(y_1 ~ x_1 + x_2)
bptest(fit_1)
```

Then, we simulate `y_2` in a manner that **does** violate assumptions, which we again verify. In this case $\epsilon \sim N(0, \sigma = |x_2|).$

```{r}
set.seed(1)
y_2 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = abs(x_2))
fit_2 = lm(y_2 ~ x_1 + x_2)
bptest(fit_2)
```

**(a)** Use the following code after changing `birthday` to your birthday.

```{r}
num_sims = 2500
p_val_1 = rep(0, num_sims)
p_val_2 = rep(0, num_sims)
birthday = 19820517
set.seed(birthday)
```

Repeat the above process of generating `y_1` and `y_2` as defined above, and fit models with each as the response `2500` times. Each time, store the p-value for testing,

\[
\beta_2 = 0,
\]

using both models, in the appropriate variables defined above. (You do not need to use a data frame as we have in the past. Although, feel free to modify the code to instead use a data frame.)

```{r}

for (i in 1:num_sims){
  y_1 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = 1)
  fit_1 = lm(y_1 ~ x_1 + x_2)
  p_val_1[i]=summary(fit_1)$coefficients[3, "Pr(>|t|)"]
  
  y_2 = 4 + 1 * x_1 + 0 * x_2 + rnorm(n = n, mean = 0, sd = abs(x_2))
  fit_2 = lm(y_2 ~ x_1 + x_2)
  p_val_2[i]=summary(fit_2)$coefficients[3, "Pr(>|t|)"]
}

```


**(b)** What proportion of the `p_val_1` values is less than 0.01? Less than 0.05? Less than 0.10? What proportion of the `p_val_2` values is less than 0.01? Less than 0.05? Less than 0.10? Arrange your results in a table. Briefly explain these results.

```{r}
p_val_1_crit = c(mean(p_val_1<0.01),mean(p_val_1<0.05), mean(p_val_1<0.10))
p_val_2_crit = c(mean(p_val_2<0.01),mean(p_val_2<0.05), mean(p_val_2<0.10))
df = data.frame("p_val_1"=p_val_1_crit, "p_val_2"=p_val_2_crit)
row.names(df) =  c("p<0.01","p<0.05","p<0.10")
df
```

Comments: On comparing p_values of both model 1 (which upholds the assumptions) amd model 2(that does not hold the assumptions), it can be seen there is a significant increase in wrong hypothesis results in the second case which is due to the fact that "Garbage In, Garbage Out"

***

## Exercise 4 (Corrosion Data)

For this exercise, we will use the `corrosion` data, which can be found in the `faraway` package. After loading the `faraway` package, use `?corrosion` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
library(faraway)
```

**(a)** Fit a simple linear regression with `loss` as the response and `Fe` as the predictor. Plot a scatterplot and add the fitted line. Check the assumptions of this model.

```{r}
mod_corr=lm(loss~Fe, data=corrosion)

plot(loss ~ Fe, data=corrosion, col="grey",
       ylab="Weight loss in mg",
       xlab="Iron content in percent",
       main="Iron content vs Weight loss",
       pch=20, cex=2) 
abline(mod_corr, lwd = 2, col = "darkorange")


par(mfrow=c(1,2))
plot(fitted(mod_corr), resid(mod_corr), col = "grey", pch = 20, cex=2,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual")
abline(h = 0, col = "darkorange", lwd = 2)


qqnorm(resid(mod_corr), main = "Q-Q Plot", col = "grey", pch = 20, cex=2)
qqline(resid(mod_corr), col = "darkorange", lwd = 2)

```

```{r}
bptest(mod_corr)
shapiro.test(resid(mod_corr)) 
```

Comments: From the plots as well as the tests it appears that both the assumptions - constant variance and Normality holds true. The p-value for both test is greater than alpha suggesting that Constant variance and Normality is not a suspect.



**(b)** Fit higher order polynomial models of degree 2, 3, and 4. For each, plot a fitted versus residuals plot and comment on the constant variance assumption. Based on those plots, which of these three models do you think are acceptable? Use a statistical test(s) to compare the models you just chose. Based on the test, which is preferred? Check the normality assumption of this model. Identify any influential observations of this model.

```{r}
mod_corr1=lm(loss~Fe + I(Fe^2), data=corrosion)
mod_corr2=lm(loss~Fe + I(Fe^2) + I(Fe^3), data=corrosion)
mod_corr3=lm(loss~Fe + I(Fe^2) + I(Fe^3) + I(Fe^4), data=corrosion)

par(mfrow=c(1,3))
plot(fitted(mod_corr1), resid(mod_corr1), col = "darkgrey", pch = 20, cex=2,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual - degree 2")
abline(h = 0, col = "darkorange", lwd = 2)

plot(fitted(mod_corr2), resid(mod_corr2), col = "darkgrey", pch = 20, cex=2,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual - degree 3")
abline(h = 0, col = "darkorange", lwd = 2)

plot(fitted(mod_corr3), resid(mod_corr3), col = "darkgrey", pch = 20, cex=2,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual - degree 4")
abline(h = 0, col = "darkorange", lwd = 2)
```

Comment: The data points is quite less to determine if the constant variance assumptions holds true. We will have to go with BP-test to further determine the assumption.

```{r}
c(bptest(mod_corr1)$p.value, bptest(mod_corr2)$p.value, bptest(mod_corr3)$p.value)
```

Comment: From the test it appears all three models have BP test p-value greater than alpha suggesting all three models have constant variance. 

```{r}
anova(mod_corr1, mod_corr2, mod_corr3)
```

Comment: The Anova test suggests that model-2 with degree 3 is most significant. Therefore I will go with the degree-3 model.

```{r}
# Test the normality of model2 (degree-3) with plots and Shapiro test
qqnorm(resid(mod_corr2), main = "Q-Q Plot", col = "darkgrey",pch = 20, cex=1.5)
qqline(resid(mod_corr2), col = "dodgerblue", lwd = 2)
shapiro.test(resid(mod_corr2))
```

Comment: Both the plots and shapiro test suggests the Normaility of the degree-3 model holds good.

```{r}
# Check for any influential points
cd_mod_corr2=cooks.distance(mod_corr2)
corrosion[cd_mod_corr2 > 4 / length(cd_mod_corr2), ]
```

Comment: It appears there are no inpluential points for the degree-3 model.

***

## Exercise 5 (Diamonds)

The data set `diamonds` from the `ggplot2` package contains prices and characteristics of 54,000 diamonds. For this exercise, use `price` as the response variable $y$, and `carat` as the predictor $x$. Use `?diamonds` to learn more.

```{r, message = FALSE, warning = FALSE}
library(ggplot2)
```

**(a)** Fit a linear model with `price` as the response variable $y$, and `carat` as the predictor $x$. Return the summary information of this model.

```{r}
mod_d =lm(price~carat, data=diamonds)
summary(mod_d)
```


**(b)** Plot a scatterplot of price versus carat and add the line for the fitted model in part **(a)**. Using a fitted versus residuals plot and/or a Q-Q plot, comment on the diagnostics. 

```{r}
par(mfrow=c(1,3)) 

plot(price~carat, data=diamonds, col="darkgrey",
       ylab="Price in US dollars",
       xlab="Weight of diamond",
       main="Price vs carat of diamonds",
       pch=20, cex=0.5) 
abline(mod_d, lwd = 2, col = "darkorange")

plot(fitted(mod_d), resid(mod_d), col = "darkgrey", pch = 20, cex=0.5,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual Plot")
abline(h = 0, col = "darkorange", lwd = 2)

qqnorm(resid(mod_d), main = "Q-Q Plot", col = "darkgrey")
qqline(resid(mod_d), col = "darkorange", lwd = 2)
```


Comment: From the fitted vs residual plot, the spread of the residuals is not the same. therefore the constant variance assumption is not valid. Also the mean of the residuals is not around zero i.e the linearity assumption is not valid. From the QQ Plot - the points of the plot do not closely follow a straight line, this would suggest that the data do not come from a normal distribution.

**(c)** Seeing as the price stretches over several orders of magnitude, it seems reasonable to try a log transformation of the response. Fit a model with a logged response, plot a scatterplot of log-price versus carat and add the line for the fitted model, then use a fitted versus residuals plot and/or a Q-Q plot to comment on the diagnostics of the model.

```{r}
qplot(price, data = diamonds, bins = 30)
```


```{r}
mod_d_log=lm(log(price)~carat, data=diamonds)

par(mfrow=c(1,3))
plot(log(price) ~ carat, data=diamonds, col="darkgrey",
       ylab="Log of price in US dollars",
       xlab="Weight of diamond",
       main="Price vs carat",
       pch=20,
       cex=0.5) 
abline(mod_d_log, lwd = 3, col = "darkorange")

plot(fitted(mod_d_log), resid(mod_d_log), col = "darkgrey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual")
abline(h = 0, col = "darkorange", lwd = 2)

qqnorm(resid(mod_d_log), main = "Q-Q Plot", col = "darkgrey")
qqline(resid(mod_d_log), col = "darkorange", lwd = 2)
```

Comment: The log-transformation did not help to remove the violation of assumptions. Both the Normality as well as the Constant variation assumption is still violated. The residual spread appears equal and around 0 for lower fitted values but sharply deviate for higher fitted values.



**(d)** Try adding log transformation of the predictor. Fit a model with a logged response and logged predictor, plot a scatterplot of log-price versus log-carat and add the line for the fitted model, then use a fitted versus residuals plot and/or a Q-Q plot to comment on the diagnostics of the model.

```{r}
mod_d_log_pred=lm(log(price)~log(carat), data=diamonds)

par(mfrow=c(1,3))
plot(log(price)~log(carat),data=diamonds, col="darkgrey",
       ylab="Log-price in US dollars",
       xlab="Log-weight of diamond",
       main="Log Price vs Log weight",
       pch=20,
       cex=0.5) 
abline(mod_d_log_pred, lwd = 3, col = "darkorange")

plot(fitted(mod_d_log_pred), resid(mod_d_log_pred), col = "darkgrey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Residual")
abline(h = 0, col = "darkorange", lwd = 2)

qqnorm(resid(mod_d_log_pred), main = "Q-Q Plot", col = "darkgrey")
qqline(resid(mod_d_log_pred), col = "darkorange", lwd = 2)

```

Comment: The log transformation of both the response and the predictor gives a much better approximation than the previous two scenarios. The residuals are almost equally spread except for higher fitted values and the points of QQ plot seem to be closely following the expected line indicating normality of errors assumption holds true.


**(e)** Use the model from part **(d)** to predict the price (in dollars) of a 3-carat diamond. Construct a 99% prediction interval for the price (in dollars).

```{r}
exp(predict(mod_d_log_pred, newdata = data.frame("carat"=3)))
exp(predict(mod_d_log_pred, newdata = data.frame("carat"=3), level=0.99, interval="prediction"))
```


